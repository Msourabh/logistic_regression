{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249456.45144278192\n",
      "vectorized version: 1.1515617370605469ms\n",
      "249456.4514427748\n",
      "for loop: 284.3210697174072ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "print(c)\n",
    "print(\"vectorized version: \"+str(1000*(toc-tic))+\"ms\")\n",
    "\n",
    "\n",
    "c = 0\n",
    "tic =time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i]*b[i]\n",
    "toc =time.time()\n",
    "print(c)\n",
    "print(\"for loop: \"+str(1000*(toc-tic))+\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(10000,)\n",
      "[2508.1099576  2480.03489749 2467.79128074 ... 2530.20952076 2502.27853526\n",
      " 2527.55627547]\n",
      "vectorized version: 46.87356948852539ms\n",
      "[[0.48365551 0.63159114 0.9449808  ... 0.43546739 0.38756564 0.71133002]\n",
      " [0.16939323 0.67437183 0.26461024 ... 0.15927956 0.49860523 0.7889601 ]\n",
      " [0.67698676 0.00721493 0.792051   ... 0.27840249 0.17932397 0.05073057]\n",
      " ...\n",
      " [0.17060365 0.5577743  0.97442424 ... 0.43393034 0.51541551 0.92233701]\n",
      " [0.84405634 0.83881726 0.31398948 ... 0.91852061 0.1993068  0.39870452]\n",
      " [0.06176452 0.97914673 0.41929626 ... 0.76283607 0.03734074 0.45888716]]\n",
      "vectorized version: 150.9377956390381ms\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(10000,10000)\n",
    "b = np.random.rand(10000)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "print(c)\n",
    "print(\"vectorized version: \"+str(1000*(toc-tic))+\"ms\")\n",
    "\n",
    "tic = time.time()\n",
    "d = np.abs(a)\n",
    "toc = time.time()\n",
    "print(d)\n",
    "print(\"vectorized version: \"+str(1000*(toc-tic))+\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99976614, 0.99997715, 0.99999828, ..., 0.99996259, 0.99996691,\n",
       "       0.9999433 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "train_x, train_y = make_blobs(n_samples=1000, centers=2, n_features=100,random_state=0)\n",
    "train_x = train_x.T\n",
    "#train = np.random.rand(100,1000) # (features,number of examples)\n",
    "#test = np.random.randint(0,2,1000)\n",
    "alpha = 0.1\n",
    "itr = 10000\n",
    "def sigma(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def logistic_regression(train,test,alpha,itr):\n",
    "    n,m=train.shape\n",
    "    W = np.zeros((n,1))\n",
    "    b = 0\n",
    "    for i in range(itr):\n",
    "        z = np.dot(W.T,train) + b\n",
    "        a = sigma(z)\n",
    "        dz = a-test\n",
    "        dw = np.dot(train,dz.T)/m\n",
    "        db = np.sum(dz)/m\n",
    "        W = W - (dw*alpha)\n",
    "        b = b - (db*alpha)\n",
    "    pred = []\n",
    "    print(a.shape)\n",
    "    for i in a.T:\n",
    "        #print(i)\n",
    "        if i[0]>0.5:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    return pred\n",
    "pred = logistic_regression(train_x,train_y,alpha,itr)\n",
    "\n",
    "#pd.concat([pd.DataFrame(test),pd.DataFrame(pred)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression():\n",
    "    def __init__(self,alpha=0.1,itr = 100):\n",
    "        self.alpha = alpha\n",
    "        self.itr = itr\n",
    "        \n",
    "    def sigma(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        n,m=X.shape\n",
    "        W = np.zeros((n,1))\n",
    "        b = 0\n",
    "        for i in range(self.itr):\n",
    "            z = np.dot(W.T,X) + b\n",
    "            a = sigma(z)\n",
    "            dz = a-y\n",
    "            dw = np.dot(X,dz.T)/m\n",
    "            db = np.sum(dz)/m\n",
    "            W = W - (dw*self.alpha)\n",
    "            b = b - (db*self.alpha)\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "    \n",
    "    def predict(self,train):\n",
    "        z = np.dot(self.W.T,train) + self.b\n",
    "        a = sigma(z)\n",
    "        pred = []\n",
    "        for i in a.T:\n",
    "            if i[0]>0.5:\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, label = make_blobs(n_samples=5000, centers=2, n_features=100,random_state=0)\n",
    "train_x,test_x,train_y,test_Y = train_test_split(data,label,test_size=0.25)\n",
    "train_x = train_x.T\n",
    "test_x = test_x.T\n",
    "model = logistic_regression()\n",
    "model.fit(train_x,train_y)\n",
    "prediction = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.concat([pd.DataFrame(test_Y),pd.DataFrame(prediction)],axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_Y,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "training_data = []\n",
    "img_size = 50\n",
    "d_path = 'keras_tutorials/dogs-vs-cats'\n",
    "categories = ['Dog','Cat']\n",
    "def create_training_data():\n",
    "    for c in categories:\n",
    "        path = os.path.join(d_path,c)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                class_num = categories.index(c)\n",
    "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                #img_array = img_array[:, :, ::-1]\n",
    "                new_image = cv2.resize(img_array,(img_size,img_size))\n",
    "                training_data.append([new_image,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    "random.shuffle(training_data)\n",
    "x = []\n",
    "y = []\n",
    "for feature, label in training_data:\n",
    "    x.append(feature)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in x:\n",
    "    X.append(i.flatten())\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_Y = train_test_split(X,y,test_size=0.25)\n",
    "train_x = train_x.T\n",
    "test_x = test_x.T\n",
    "model = logistic_regression(itr = 1000)\n",
    "model.fit(train_x,train_y)\n",
    "prediction = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49296"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_Y,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
